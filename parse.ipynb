{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nishanth\n"
     ]
    }
   ],
   "source": [
    "cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "txt_file=r\"SemEval2018-T3-train-taskA_emoji_ironyHashtags.txt\"\n",
    "csv_file=r\"data1.csv\"\n",
    "in_txt= csv.reader(open(txt_file,'r',errors='ignore'),delimiter='\\t')\n",
    "out_csv=csv.writer(open(csv_file,'w'))\n",
    "out_csv.writerows(in_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import emoji\n",
    "import re\n",
    "import nltk\n",
    "import csv\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "with open('data1.csv')as csvfile:\n",
    "    de_emojize=emoji.demojize(csvfile.read())\n",
    "    commonurl_str = re.sub(r'\\w+:\\/{2}[\\d\\w-]+(\\.[\\d\\w-]+)*(?:(?:\\/[^\\s/]*))*', 'http://someurl', de_emojize)\n",
    "    replace_username=re.sub('(?<=^|(?<=[^a-zA-Z0-9-_\\.]))@([A-Za-z]+[A-Za-z0-9-_]+)','@someuser',commonurl_str)\n",
    "    input_txt=replace_username+'\\n'\n",
    "list=input_txt.splitlines()\n",
    "\n",
    "with open('preproc_input.csv','w',newline='') as csvfile:\n",
    "    writer=csv.writer(csvfile)\n",
    "    for i in list:\n",
    "        writer.writerows([[i]])\n",
    "        \n",
    "input_tokenized=nltk.word_tokenize(input_txt)\n",
    "input_posTag=nltk.pos_tag(input_tokenized)\n",
    "with open('pos_tag.csv','w',newline='') as csvfile:\n",
    "    writer=csv.writer(csvfile)\n",
    "    for i in list:\n",
    "        writer.writerows([[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[((\"''\", \"''\"), 13319), (('@', 'someuser'), 2322), ((':', '//someurl'), 937), (('http', ':'), 909), ((',', \"''\"), 892), ((',', '@'), 854), (('#', 'not'), 832), (('``', \"''\"), 712), (('someuser', '@'), 685), (('//someurl', \"''\"), 683), (('.', '#'), 658), (('#', 'sarcasm'), 653), (('``', '``'), 515), ((\"''\", '``'), 509), (('sarcasm', \"''\"), 395), (('not', \"''\"), 356), (('#', 'irony'), 332), (('!', '!'), 332), (('.', \"''\"), 325), ((\"''\", '@'), 322), ((',', 'I'), 305), (('!', '#'), 287), (('not', '#'), 220), (('I', \"'m\"), 198), ((',', '#'), 198), (('irony', \"''\"), 180), (('#', 'Not'), 168), (('sarcasm', '#'), 156), (('someuser', \"''\"), 135), (('someuser', ':'), 131), (('#', 'NOT'), 131), (('...', 'http'), 123), (('!', \"''\"), 118), (('in', 'the'), 118), (('?', '#'), 116), (('#', 'Sarcasm'), 115), (('someuser', 'I'), 110), (('#', 'Irony'), 103), (('?', \"''\"), 97), (('do', \"n't\"), 97), (('//someurl', '#'), 97), ((\"''\", '#'), 94), (('I', 'love'), 88), (('...', '#'), 87), (('it', \"'s\"), 87), (('someuser', '#'), 86), (('of', 'the'), 83), (('to', 'be'), 78), (('.', 'I'), 77), (('It', \"'s\"), 77)]\n"
     ]
    }
   ],
   "source": [
    "##bigrams\n",
    "import nltk\n",
    "from nltk.collocations import *\n",
    "\n",
    "with open('preproc_input.csv')as csvfile:\n",
    "    data= csvfile.read()\n",
    "    tokens = nltk.word_tokenize(data)\n",
    "    bgs = nltk.bigrams(tokens)\n",
    "\n",
    "#compute frequency distribution for all the bigrams in the text\n",
    "    fdist = nltk.FreqDist(bgs)\n",
    "    print(fdist.most_common(50))\n",
    "    #print(fdist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6089 6089\n"
     ]
    }
   ],
   "source": [
    "#count hashtags\n",
    "\n",
    "with open('preproc_input.csv')as csvfile:\n",
    "    c,j,k=0,0,0\n",
    "    data= csvfile.read()\n",
    "    for i in data.splitlines():\n",
    "        c=i.count('#')\n",
    "        j+=c\n",
    "        #print(c)\n",
    "    k=data.count('#')\n",
    "    print(j,k)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
